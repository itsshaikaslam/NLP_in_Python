{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first stage of any NLP project is to extract the required textual data. This text data is usually unstructured and stored in various locations and formats.\n",
    "\n",
    "The purpose of this notebook is to show how to extract text data from the most common sources.\n",
    "\n",
    "We will cover text extraction from the following sources:\n",
    "1. Tweets\n",
    "2. Word Documents\n",
    "3. PDFs\n",
    "4. Text from Images\n",
    "5. CSV files\n",
    "6. Excel files\n",
    "7. Facebook Posts\n",
    "8. RSS Feeds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract Tweets\n",
    "***\n",
    "Tweets can be extracted and fed into an NLP model to get a wider public view. We shall use the `tweepy` library to extract the tweets for the target words. \n",
    "\n",
    "First you need to generate the required tokens and secret security information:\n",
    "\n",
    "* Go to [this link](https://apps.twitter.com/) and click \"Create New App\"\n",
    "* Choose Create your Twitter Application, fill in the details and you will get your token from \"Keys and Access Tokens\" tab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tweepy\n",
    "from tweepy.streaming import StreamListener\n",
    "from tweepy import OAuthHandler\n",
    "from tweepy import Stream\n",
    "\n",
    "auth = tweepy.auth.OAuthHandler( enter_key_consumer, \\\n",
    "                               enter_secret_consumer )\n",
    "\n",
    "auth.set_access_token( token, secret )\n",
    "api = tweepy.API( auth )\n",
    "\n",
    "def get_tweets( api, keywords, count ):\n",
    "    return api.search( q=keywords, result_type='recent', \\\n",
    "                     lang='en', count=count )\n",
    "\n",
    "tweets = get_tweets( api, ['FinTechExplained', 'MachineLearning'], 5)\n",
    "\n",
    "for tweet in tweets:\n",
    "    print(tweet.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to Read a Word Document\n",
    "***\n",
    "Use the `docx` library to read and extract text from the word documents\n",
    "\n",
    "`pip install docx`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_text = []\n",
    "doc = docx.Document( filename )\n",
    "for paragraph in doc.paragraphs:\n",
    "    all_text.append( para.text )\n",
    "    \n",
    "print('\\n'.join(all_text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to Read a PDF Document\n",
    "***\n",
    "Use the `PyPDF2` library to work with PDFs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reader = PyPDF2.PdfFileReader( open( file_name, 'rb' ))\n",
    "print(pdfReader.getPage(0).extractText())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read text from Image\n",
    "***\n",
    "Use the `pytesseract` library to process and read text from images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import Image\n",
    "from tesseract import image_to_string\n",
    "print( image_to_string(Image.open(image_to_string), lang='en'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read Text from a CSV File\n",
    "***\n",
    "Use the `pandas` library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "dataframe = pd.read_csv(file_path, sep=',', delimiter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read Text from Excel Spreadsheet\n",
    "***\n",
    "Use the `pandas` library to read text from an excel spreadsheet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_frame = pd.read_excel( file, sheet_name )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract Posts from Facebook\n",
    "***\n",
    "The first step is to get the required token, by navigating to [this link](developers.facebook.com/tools/explorer).\n",
    "\n",
    "Then go to My apps, and add a new app and create your app ID.\n",
    "\n",
    "Then get your user access token from [here](developers.facebook.com/tools/explorer)\n",
    "\n",
    "You can extend the expiration date of the user access token by visiting [this link](developers.facebook.com/tools/accesstoken)\n",
    "\n",
    "Then, install the libraries:\n",
    "`pip install facebook-sdk`\n",
    "\n",
    "Now we can use code to get the 5 posts of a specific user:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import facebook\n",
    "import requests\n",
    "\n",
    "token_url = 'https://graph.facebook.com/oauth/access_token'\n",
    "params = dict( client_id, client_secret , grant_type='client_credentials')\n",
    "\n",
    "token_response = requests.get( token_url, params)\n",
    "graph = facebook.GraphAPI( token_response.text.split('=')[1])\n",
    "posts = graph.get_connections( graph.get_object(user_id)['id'],\\\n",
    "                             'posts?limit=5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract from RSS Feed\n",
    "***\n",
    "Install the `feedparser` library to extract the RSS feeds:\n",
    "\n",
    "`pip install feedparser`\n",
    "\n",
    "Then we can use the feedparser library to extract the keys:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import feedparser\n",
    "feed = feedparser.parse(rss_feed_url)\n",
    "for entry in feed.entries:\n",
    "    print(entry.keys())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "280.6px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
